{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adaptative Media Processing HW2\n",
    "\n",
    "## __Methods__\n",
    "A. Optimal Linear Associative Memory (OLAM). <br>\n",
    "B. Fisher’s linear discriminator (FLD)\n",
    "\n",
    "## __Dataset__\n",
    "Fisher’s iris data from the Machine Learning Repository at UC Irvine <br>\n",
    "http://archive.ics.uci.edu/ml/datasets/Iris \n",
    "\n",
    "## __Experiment__\n",
    "1) The data of each class were divided in half.\n",
    "2) Half of it were used to train each classifier and the other half to test them.\n",
    "3) The accuracy of the testing was collected\n",
    "4) Step 1-3 were repeated 100 times for a t-test with power = 1 (delta = 0.05)\n",
    "\n",
    "## __Result__\n",
    "method: mean (standard deviation)<br>\n",
    "olam: 0.803 (0.036) <br>\n",
    "fld:  0.946 (0.023)\n",
    "\n",
    "__T-test__\n",
    "H_0 : mean_fld <= mean_olam\n",
    "H_1 : mean_fld >  mean_olam\n",
    "\n",
    "p-value < 2.2e-16\n",
    "\n",
    "## __Conclusion__\n",
    "There is a significant difference in the accuracy, suggesting that Fisher's classifier is better than OLAM on this dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_training_set(classes, sizes):\n",
    "    train = np.array([], dtype=bool)\n",
    "    for i, c in enumerate(classes):\n",
    "        mask = np.array([True]*int(sizes[i]/2) + [False]*int(sizes[i]/2))\n",
    "        np.random.shuffle(mask)\n",
    "        train = np.append(train, mask)\n",
    "        \n",
    "    return train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OLAM(object):\n",
    "    def __init__(self):\n",
    "        self._positive = 0\n",
    "        self._total    = 0\n",
    "        self.accuracy  = 0\n",
    "        self.M = np.array([])\n",
    "        \n",
    "    def train(self, X, Y):\n",
    "        X_ = np.linalg.pinv(np.transpose(np.matrix(X)))\n",
    "        Y_ = np.transpose(np.matrix(Y))\n",
    "        self.M = Y_ * X_\n",
    "        \n",
    "    def classify(self, X):\n",
    "        Y_ = self.M * np.transpose(np.array([X])) \n",
    "        return np.argmax(Y_)\n",
    "    \n",
    "    def test(self, X, Y):\n",
    "        self._total = len(X)\n",
    "        for x, y in zip(np.array(X),np.array(Y)):\n",
    "            y_ = self.classify(x)\n",
    "            if(y_ == np.argmax(y)):\n",
    "                self._positive += 1\n",
    "                \n",
    "        self.accuracy = self._positive/self._total\n",
    "        return self.accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class F_LD(object):\n",
    "    def __init__(self):\n",
    "        self._positive = 0\n",
    "        self._total    = 0\n",
    "        self.accuracy  = 0\n",
    "        \n",
    "        self.M = np.array([])\n",
    "    \n",
    "    def train(self, data, itr, its):\n",
    "        self._classes = data[\"class\"].unique()\n",
    "\n",
    "        # calculate mean_class and mean_global\n",
    "        self._mean_c = np.array([[data[data[\"class\"] == cls].mean().iloc[:itr]] for cls in self._classes])\n",
    "        self._mean_g = np.mean(self._mean_c, axis=0)\n",
    "        \n",
    "        # Sw: within-class covariance \n",
    "#         self._Sw = [np.sum([np.transpose((x - self._mean_c[i]))*(x - self._mean_c[i])\n",
    "#                            for x in np.matrix(data[data[\"class\"] == cls].iloc[:,:4])])\n",
    "#                                 for i, cls in enumerate(self._classes)]\n",
    "\n",
    "        R = [np.zeros((4, 4)) for i in range(len(classes))]\n",
    "        for i, cls in enumerate(classes):\n",
    "            for x in np.matrix(data[data[\"class\"] == cls].iloc[:,:4]):\n",
    "                tmp_ = x - self._mean_c[i]\n",
    "                tmp_ = np.transpose(tmp_) * tmp_\n",
    "                R[i] += tmp_\n",
    "                \n",
    "        self._Sw = sw = R[0] + R[1] + R[2]\n",
    "        \n",
    "        # Sb: between-class covariance\n",
    "        self._Sb = np.sum([len(np.matrix(data[data[\"class\"] == cls]))*(self._mean_c[i] - self._mean_g)*np.transpose((self._mean_c[i] - self._mean_g)) \n",
    "                     for i, cls in enumerate(classes)], axis=0)\n",
    "        \n",
    "        val, vec = np.linalg.eig(np.linalg.pinv(self._Sw) * self._Sb)\n",
    "        \n",
    "        # W\n",
    "        self._W = np.transpose(vec[np.argmax(val)].reshape(4,1))\n",
    "        \n",
    "        # Projections\n",
    "        self._p1 = self._W * self._mean_c[0]\n",
    "        self._p2 = self._W * self._mean_c[1] \n",
    "        self._p3 = self._W * self._mean_c[2]\n",
    "        \n",
    "    def classify(self, X):\n",
    "        p_ = self._W * X\n",
    "        return np.argmin([np.linalg.norm(p_ - self._p1), np.linalg.norm(p_ - self._p2), np.linalg.norm(p_ - self._p3)])\n",
    "    \n",
    "    def test(self, X, Y):\n",
    "        self._total = len(X)\n",
    "        for x, y in zip(np.array(X),np.array(Y)):\n",
    "            y_ = self.classify(x)\n",
    "            if(y_ == np.argmax(y)):\n",
    "                self._positive += 1\n",
    "                \n",
    "        self.accuracy = self._positive/self._total\n",
    "        return self.accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "header  = [\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\", \"class\"]\n",
    "data    = pd.read_csv(\"data/iris.data\", names=header)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprossing:\n",
    "1. setosa -> [1,0,0]\n",
    "2. versicolor -> [0,1,0]\n",
    "3. virginica -> [0,0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = data[\"class\"].unique()\n",
    "sizes   = [sum(data[\"class\"] == c) for c in classes]\n",
    "mask_cls = [data[\"class\"] == c for c in classes]\n",
    "\n",
    "#data = data_raw.copy().drop(columns = [\"class\"])\n",
    "data[\"Iris-setosa\"] = list(map(int, mask_cls[0]))\n",
    "data[\"Iris-versicolor\"] = list(map(int, mask_cls[1]))\n",
    "data[\"Iris-virginica\"] = list(map(int, mask_cls[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OLAM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean(std)\n",
      " 0.8029333333333333 ( 0.03620092079860217 )\n"
     ]
    }
   ],
   "source": [
    "rep = 100\n",
    "acc_olam = []\n",
    "for i in range(0, rep):\n",
    "    # make train test set\n",
    "    train = make_training_set(classes, sizes)\n",
    "    test  = np.array([not x for x in train])\n",
    "\n",
    "    train_x, train_y = data[train].iloc[:,:4], data[train].iloc[:,5:] #x: features, y:encoded_class\n",
    "    test_x,  test_y  = data[test].iloc[:,:4], data[test].iloc[:,5:]\n",
    "\n",
    "    # initialize model\n",
    "    model = OLAM()\n",
    "\n",
    "    # train\n",
    "    model.train(train_x, train_y)\n",
    "\n",
    "    # test\n",
    "    model.test(test_x, test_y)\n",
    "    \n",
    "    acc_olam += [model.accuracy]\n",
    "#     print(i, model.accuracy, sep=\",\")\n",
    "\n",
    "print(\"Mean(std)\\n\", np.mean(acc_olam), \"(\",np.std(acc_olam),\")\")\n",
    "np.savetxt(\"acc_olam.txt\", acc_olam, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FISHER'S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean(std)\n",
      " 0.946 ( 0.022578258962501468 )\n"
     ]
    }
   ],
   "source": [
    "rep = 100\n",
    "acc_fld = []\n",
    "for i in range(0, rep):\n",
    "    # make train test set\n",
    "    train = make_training_set(classes, sizes)\n",
    "    test  = np.array([not x for x in train])\n",
    "\n",
    "    train_x, train_y = data[train].iloc[:,:4], data[train].iloc[:,5:] #x: features, y:encoded_class\n",
    "    test_x,  test_y  = data[test].iloc[:,:4], data[test].iloc[:,5:]\n",
    "\n",
    "    # initialize model\n",
    "    model = F_LD()\n",
    "\n",
    "    # train\n",
    "    model.train(data[train], 4, 5)\n",
    "\n",
    "    # test\n",
    "    model.test(test_x, test_y)\n",
    "    \n",
    "    acc_fld += [model.accuracy]\n",
    "    #print(i+1, model.accuracy, sep=\",\")\n",
    "print(\"Mean(std)\\n\", np.mean(acc_fld), \"(\",np.std(acc_fld),\")\")\n",
    "np.savetxt(\"acc_fld.txt\", acc_fld, delimiter=\",\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
